{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from prediction import run_indobert_pipeline, text_cleansing\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load model & tokenizer\n",
    "# @st.cache_resource\n",
    "def load_model():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"./src/indobert_model\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./src/indobert_tokenizer\")\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = load_model()\n",
    "\n",
    "st.title(\"üéì Sentiment Analysis on Student Reviews in Higher Education\")\n",
    "\n",
    "st.write(\"üìÅ Upload a CSV file with a column named `text` containing student reviews:\")\n",
    "\n",
    "students_experience = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
    "\n",
    "if students_experience is not None:\n",
    "    df = pd.read_csv(students_experience)\n",
    "\n",
    "    if 'text' in df.columns and df['text'].dropna().iloc[0] is not None and isinstance(df['text'].dropna().iloc[0], str):\n",
    "        st.subheader(\"Sample of Uploaded Reviews\")\n",
    "        st.write(df['text'].head(5))\n",
    "\n",
    "        if st.button(\"Predict Sentiment\", icon='üîç'):\n",
    "            with st.spinner(\"Processing and predicting...\"):\n",
    "                df['cleaned_text'] = df['text'].apply(text_cleansing)\n",
    "                predictions = run_indobert_pipeline(df, model, tokenizer)\n",
    "                df['sentiment'] = predictions\n",
    "\n",
    "                # Show distribution\n",
    "                sentiment_counts = df['sentiment'].value_counts(normalize=True) * 100\n",
    "                st.subheader(\"üìä Sentiment Distribution\")\n",
    "                st.bar_chart(sentiment_counts)\n",
    "\n",
    "                st.subheader(\"üîé Preview of Labeled Data\")\n",
    "                st.write(df[['text', 'sentiment']].head(10))\n",
    "    else:\n",
    "        st.error(\"‚ùó Make sure the uploaded CSV contains a 'text' column with valid strings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/thesis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./src/models/indobert_model\", local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"./src/models/indobert_tokenizer\", local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"./src/models/indobert_model\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/Caskroom/miniconda/base/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# model.predict(\"Saya suka dengan lingkungan kampusnya\")\n",
    "import torch\n",
    "\n",
    "id2label = {0: \"Negative\", 1: \"Positive\"}\n",
    "\n",
    "model.eval()\n",
    "\n",
    "texts = [\"Saya suka dengan lingkungan kampus\"]\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    preds = torch.argmax(outputs.logits, dim=1)\n",
    "    labels = [id2label[int(p)] for p in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/alicia.siahaya/Documents/Alice Tiket 2025/Thesis/streamlit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"CWD:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(22888) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04_streamlit.ipynb \u001b[34m__pycache__\u001b[m\u001b[m        prediction.py\n",
      "\u001b[34mCODES\u001b[m\u001b[m              app.py             \u001b[34msrc\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(22859) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mindobert_model\u001b[m\u001b[m     \u001b[34mindobert_tokenizer\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls src/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
